[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/release/python-376/)
[![TensorFlow 2.1](https://img.shields.io/badge/tensorflow-2.1.1-blue.svg)](https://github.com/tensorflow/tensorflow/releases)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/kumar-shridhar/APOLLO-1/blob/master/LICENSE)

![.](/Resources/Logo.png) 


# Project APOLLO

APOLO stands for APplication Of Learning to Levitate Opportune. In this series of projects, our objective was to use deep learning in solving the common problems and to build a python app (open source). Project APOLLO is run with the help of volunteers.

---------------------------------------------------------------------------------------------------------

## APOLLO-1: Online-toxicity-detection

This is the first Project of the series, Online-Toxicity-Detectioon. Goal of this project was to build a web-based python app that takes a link of a social media platform as an input, and detect the toxicity in the comments as output. The Project is run in phases. First phase of the project was from 16th May 2020 to 1st June 2020. 

##### Project Contributors: ##### 
[Naveed Akram](https://github.com/n-akram), [Ritu Yadav](https://github.com/RituYadav92), [Kumar Shridhar](https://github.com/kumar-shridhar), [Ashutosh Mishra](https://github.com/ashutoshmishra1014), [Venkatesh Iyer](https://github.com/venkyiyer), [Sadique Adnan](https://github.com/sadique-adnan)

##### Read more about this project in our [blog](https://medium.com/@shridhar743/are-you-indulging-in-a-toxic-conversation-c67708b8895). 
##### Access the project Github [here](https://github.com/kumar-shridhar/Online-Toxicity-Detection). 

---------------------------------------------------------------------------------------------------------

